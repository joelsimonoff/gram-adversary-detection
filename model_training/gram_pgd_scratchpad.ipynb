{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>WRN: Cifar10</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable, grad\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.parameter import Parameter\n",
    "import pandas as pd\n",
    "import utils.calculate_log as callog\n",
    "from utils.wrn import WideResNet\n",
    "\n",
    "from utils.detector import Detector, gram_margin_loss, new_gram_margin_loss, ScoreDetector\n",
    "import utils.attacks as attacks\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "torch_model = WideResNet(depth=40, widen_factor=2, num_classes=10)\n",
    "\n",
    "# torch_model.load(path=\"checkpoints_score_v1/cifar10_wrn_baseline_epoch_99.pt\")\n",
    "# torch_model.load(path=\"benchmark_ckpts/cifar10_reg_training_99.pt\")\n",
    "torch_model.load(path=\"checkpoints_margin_01/cifar10_wrn_baseline_epoch_99.pt\")\n",
    "# torch_model.load(path=\"benchmark_ckpts/cifar10_style_epoch_99.pt\")\n",
    "# torch_model.load(path=\"checkpoints_style_fine_tuning/cifar10_wrn_baseline_epoch_2.pt\")\n",
    "torch_model.cuda()\n",
    "torch_model.params = list(torch_model.parameters())\n",
    "torch_model.eval()\n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In-distribution Datasets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "# mean = np.array([[125.3/255, 123.0/255, 113.9/255]]).T\n",
    "\n",
    "# std = np.array([[63.0/255, 62.1/255.0, 66.7/255.0]]).T\n",
    "# normalize = transforms.Normalize((125.3/255, 123.0/255, 113.9/255), (63.0/255, 62.1/255.0, 66.7/255.0))\n",
    "\n",
    "normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "        \n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.CenterCrop(size=(32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('~/datasets/cifarpy', train=True, download=True,\n",
    "                   transform=transform_train),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('~/datasets/cifarpy', train=False, transform=transform_test),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "detector_data_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "data_train = list(torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('~/datasets/cifarpy', \n",
    "                     train=True, \n",
    "                     transform=detector_data_transform, \n",
    "                     download=True),\n",
    "        batch_size=1, shuffle=False))\n",
    "\n",
    "data_test = list(torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('~/datasets/cifarpy', \n",
    "                     train=False, \n",
    "                     transform=detector_data_transform, \n",
    "                     download=True),\n",
    "        batch_size=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_batch(bxs):\n",
    "    pil = transforms.ToPILImage()\n",
    "    return torch.squeeze(torch.stack([transform_test(pil(bx)) for bx in bxs]), dim=1)\n",
    "\n",
    "def get_batches(d, batch_size=32):\n",
    "    bx = []\n",
    "    by = []\n",
    "    tens = transforms.ToTensor()\n",
    "    for idx in range(0,len(d),batch_size):\n",
    "        bx_batch = torch.squeeze(torch.stack([tens(x[0]) for x in d[idx:idx+batch_size]]),dim=1)\n",
    "        bx.append(bx_batch)\n",
    "        by.append(torch.Tensor([x[1] for x in d[idx:idx+batch_size]]).type(torch.LongTensor))\n",
    "    \n",
    "    return bx, by\n",
    "\n",
    "def advs_p(p, bxs, bys, nrof_batches=None):\n",
    "    if nrof_batches is None:\n",
    "        nrof_batches = len(bxs)\n",
    "        \n",
    "    advs = []\n",
    "    for i in tqdm(range(len(bxs))):\n",
    "        if i >= nrof_batches:\n",
    "            break\n",
    "        \n",
    "        _, feats_reg = torch_model.gram_forward((bxs[i]*2 - 1).cuda())\n",
    "        advs_batch = p(torch_model, bxs[i].cuda(), bys[i].cuda())\n",
    "\n",
    "        advs.append(advs_batch)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return advs\n",
    "\n",
    "def adversarial_acc(advs, bys):\n",
    "    torch_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(advs)):\n",
    "        pipelined = pipeline_batch(advs[i].cpu())\n",
    "\n",
    "        x = pipelined.cuda()\n",
    "        y = bys[i].numpy()\n",
    "\n",
    "        correct += (y==np.argmax(torch_model(x).detach().cpu().numpy(),axis=1)).sum()\n",
    "        total += y.shape[0]\n",
    "\n",
    "\n",
    "    print(\"Adversarial Test Accuracy: \", correct/total)\n",
    "    \n",
    "def ds_grouped(bxs, bys):\n",
    "    ds = []\n",
    "    for i in range(len(bxs)):\n",
    "        pipelined = pipeline_batch(bxs[i].cpu())\n",
    "        for j in range(len(bxs[i])):\n",
    "            ds.append((pipelined[j], bys[i][j]))\n",
    "    return ds\n",
    "\n",
    "def adversarial_scores(detector, advs_batches, pbar = lambda x, total=None: x):\n",
    "    auroc = []\n",
    "    for batch in pbar(advs_batches):\n",
    "        auroc.append(detector.compute_ood_deviations_batch(batch*2 - 1)[\"AUROC\"])\n",
    "    \n",
    "    return np.mean(auroc)\n",
    "\n",
    "def model_accuracy():\n",
    "    torch_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,y in test_loader:\n",
    "        x = x.cuda()\n",
    "        y = y.numpy()\n",
    "        correct += (y==np.argmax(torch_model(x).detach().cpu().numpy(),axis=1)).sum()\n",
    "        total += y.shape[0]\n",
    "        \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Results </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector(torch_model, data_train, data_test, 512, pbar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = attacks.PGD(epsilon=8./255, num_steps=10, step_size=2./255).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating L_Inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e322a79d70b7452191c81d5539a55b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adversarial Test Accuracy:  0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb4e1f16f164296b34ce6110a996fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9675182555379747"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10 = list(datasets.CIFAR10('~/datasets/cifarpy', train=False))\n",
    "\n",
    "print(\"Calculating L_Inf\")\n",
    "xs, ys = get_batches(cifar10, batch_size=128)\n",
    "# pinf = PGD()\n",
    "pinf = adversary\n",
    "# pinf = PGD_margin().cuda()\n",
    "advs_inf = advs_p(pinf, xs, ys)\n",
    "\n",
    "adversarial_acc(advs_inf, ys)\n",
    "\n",
    "adversarial_scores(detector, advs_inf, pbar=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = list(datasets.CIFAR10('~/datasets/cifarpy', train=False))\n",
    "random.shuffle(cifar10)\n",
    "xs, ys = get_batches(cifar10, batch_size=64)\n",
    "\n",
    "dt = ScoreDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(layer):\n",
    "    b, ch, h, w = layer.size()\n",
    "    features = layer.view(b, ch, w * h)\n",
    "    gram = torch.matmul(features, features.transpose(1, 2))\n",
    "    \n",
    "    return gram /(ch * h * w)\n",
    "\n",
    "def style_loss(lhs, rhs):\n",
    "    loss = 0.0\n",
    "    for i in range(len(lhs)):\n",
    "        loss += (gram_matrix(lhs[i]) - gram_matrix(rhs[i])).pow(2).sum()\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def calc_vals(x, y):\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    \n",
    "    logits_reg, feats_reg = torch_model.gram_forward(x*2 - 1)\n",
    "    \n",
    "#     adv_x = attacker_smart(torch_model, x, y, feats_reg)\n",
    "    adv_x = attacker_smart(torch_model, x, y)\n",
    "#     adv_x = attacker_naive(torch_model, x, y)\n",
    "    logits_adv, feats_adv = torch_model.gram_forward(adv_x * 2 - 1)\n",
    "    \n",
    "    x, y = x.cpu(), y.cpu()\n",
    "    adv_x = adv_x.cpu()\n",
    "    logits_adv = logits_adv.cpu()\n",
    "    \n",
    "#     print(score(feats_adv) - score(feats_reg))\n",
    "    \n",
    "    acc = (y==torch.max(logits_adv,dim=1)[1]).numpy().mean()\n",
    "    auroc, auroc_failed = detector.compute_auroc_advs(logits_adv.detach(), feats_adv, y)\n",
    "    \n",
    "    return feats_reg, feats_adv, auroc, auroc_failed, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(x, y, margin=20, smart=True):\n",
    "    feats_reg, feats_adv, auroc, auroc_failed, acc = calc_vals(x, y)\n",
    "    \n",
    "#     return style_loss(feats_reg, feats_adv).cpu()\n",
    "    return auroc, auroc_failed, acc, feats_reg, feats_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e140a535924c410c8265e095ed27663a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Cent: 1.136912226676941, Gram: tensor([9.8307e-10], device='cuda:2'), Total Loss: tensor([1.1369], device='cuda:2')\n",
      "Step: 1, Cent: 4.336390495300293, Gram: tensor([0.0071], device='cuda:2'), Total Loss: tensor([-2.7547], device='cuda:2')\n",
      "Step: 2, Cent: 3.5634055137634277, Gram: tensor([8.9993e-06], device='cuda:2'), Total Loss: tensor([3.5544], device='cuda:2')\n",
      "Step: 3, Cent: 8.377714157104492, Gram: tensor([0.0081], device='cuda:2'), Total Loss: tensor([0.2438], device='cuda:2')\n",
      "Step: 4, Cent: 5.021505355834961, Gram: tensor([8.9888e-07], device='cuda:2'), Total Loss: tensor([5.0206], device='cuda:2')\n",
      "Step: 5, Cent: 9.927082061767578, Gram: tensor([0.0063], device='cuda:2'), Total Loss: tensor([3.5932], device='cuda:2')\n",
      "Step: 6, Cent: 6.349969387054443, Gram: tensor([1.7116e-06], device='cuda:2'), Total Loss: tensor([6.3483], device='cuda:2')\n",
      "Step: 7, Cent: 11.239173889160156, Gram: tensor([0.0054], device='cuda:2'), Total Loss: tensor([5.8508], device='cuda:2')\n",
      "Step: 8, Cent: 7.464690685272217, Gram: tensor([1.6031e-06], device='cuda:2'), Total Loss: tensor([7.4631], device='cuda:2')\n",
      "Step: 9, Cent: 13.24970531463623, Gram: tensor([0.0035], device='cuda:2'), Total Loss: tensor([9.7810], device='cuda:2')\n",
      "0.739013671875\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "#     attacker_smart = attacks.PGD_Gram(detector, \n",
    "#                               num_steps=10, \n",
    "#                               epsilon=8./255, \n",
    "#                               step_size=2.0/255, \n",
    "#                               verbose=True)\n",
    "    \n",
    "#     attacker_smart = attacks.PGD_margin(margin = 10,\n",
    "#                                 epsilon=8./255, \n",
    "#                                 num_steps=10, \n",
    "#                                 step_size=2/255, \n",
    "#                                 verbose=True)\n",
    "#     margin = 10\n",
    "#     attacker_smart = PGD_margin(epsilon=8./255, \n",
    "#                                    num_steps=0, \n",
    "#                                    step_size=2./255, \n",
    "#                                    margin=margin,\n",
    "#                                    margin_scale=1,\n",
    "#                                 verbose=True)\n",
    "\n",
    "    attacker_smart = attacks.PGD_score(score_scale=1000,\n",
    "                                    epsilon=8./255, \n",
    "                                   num_steps=10, \n",
    "                                   step_size=2./255, \n",
    "                                    verbose=True)\n",
    "\n",
    "    attacker_naive = attacks.PGD(epsilon=8./255, num_steps=10, step_size=2./255)\n",
    "    \n",
    "    auroc, auroc_failed, acc = [], [], []\n",
    "    for i, x in tqdm(enumerate(xs), total=len(xs)):\n",
    "        a, a_f, accuracy, feats_reg, feats_adv = process_batch(x, ys[i])\n",
    "        auroc.append(a)\n",
    "        auroc_failed.append(a_f)\n",
    "        acc.append(accuracy)\n",
    "        \n",
    "#         labels = np.array([0] * len(feats_reg[0]) + [1] * len(feats_adv[0]))\n",
    "#         scores = np.concatenate((score(feats_reg, False).cpu(), score(feats_adv, False).cpu()))\n",
    "\n",
    "#         fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "#         auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        auc = dt.calc_auroc(feats_reg, feats_adv)\n",
    "        print(auc)\n",
    "        \n",
    "        if i >= 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9993509090909091, 0.9996, 0.140625)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(auroc).mean(), np.array(auroc_failed).mean(), np.array(acc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_p(temp):\n",
    "    normalizer = torch.prod(torch.tensor(temp.shape[1:]))\n",
    "    temp = temp.reshape(temp.shape[0],temp.shape[1],-1)\n",
    "    temp = (torch.matmul(temp,temp.transpose(dim0=2,dim1=1))).reshape(temp.shape[0],-1).sum(dim=1)\n",
    "    \n",
    "    return temp/normalizer\n",
    "\n",
    "def get_deviations(feat_list, mean=True):\n",
    "    batch_deviations = []\n",
    "    for L,feat_L in enumerate(feat_list):\n",
    "        dev = 0\n",
    "\n",
    "        g_p = G_p(feat_L)\n",
    "        g_p = g_p\n",
    "        dev = g_p\n",
    "        \n",
    "        if mean:   \n",
    "            batch_deviations.append(dev.mean())\n",
    "        else:\n",
    "            batch_deviations.append(dev)\n",
    "        \n",
    "    return batch_deviations\n",
    "\n",
    "def score(feats, mean=True):\n",
    "    devs = get_deviations(feats, mean)\n",
    "    \n",
    "    return torch.stack(devs).mean(dim=0).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGD_score(nn.Module):\n",
    "    def __init__(self, epsilon=8./255, num_steps=10, step_size=2./255, score_scale = 100, verbose=False, detector=ScoreDetector()):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "        self.verbose = verbose\n",
    "        self.detector = detector\n",
    "        self.score_scale = score_scale\n",
    "\n",
    "    def forward(self, model, bx, by):\n",
    "        \"\"\"\n",
    "        :param model: the classifier's forward method\n",
    "        :param bx: batch of images\n",
    "        :param by: true labels\n",
    "        :return: perturbed batch of images\n",
    "        \"\"\"\n",
    "        adv_bx = bx.detach()\n",
    "        adv_bx += torch.zeros_like(adv_bx).uniform_(-self.epsilon, self.epsilon)\n",
    "        \n",
    "        for i in range(self.num_steps):\n",
    "            adv_bx.requires_grad_()\n",
    "            \n",
    "            with torch.enable_grad():\n",
    "                logits, feats_adv = model.gram_forward(adv_bx * 2 - 1)\n",
    "                gram_score = F.softplus(self.detector.score(feats_adv) - .125, beta=100)\n",
    "                cent_loss = F.cross_entropy(logits, by, reduction='mean').cuda()\n",
    "                \n",
    "                loss = cent_loss - self.score_scale * gram_score\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(\"Step: {}, Cent: {}, Gram: {}, Total Loss: {}\".format(i, cent_loss.data, gram_score.data, loss.data))\n",
    "            grad = torch.autograd.grad(loss, adv_bx, only_inputs=True)[0]\n",
    "            adv_bx = adv_bx.detach() + self.step_size * torch.sign(grad.detach())\n",
    "            adv_bx = torch.min(torch.max(adv_bx, bx - self.epsilon), bx + self.epsilon).clamp(0, 1)\n",
    "            \n",
    "        return adv_bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    _, f = torch_model.gram_forward((xs[0].cuda() + torch.zeros_like(xs[0].cuda()).uniform_(-8/255, 8/255)).cuda() * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = cpu(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-188.3312,  -33.0728, -166.5293, -265.6161, -301.9734, -202.8130,\n",
       "        -199.3248, -244.1910, -208.7040, -455.5402, -157.3834, -260.6914,\n",
       "        -126.7905, -200.8347, -286.7367, -125.9502,  -28.4041, -436.9200,\n",
       "        -415.3741, -173.4412, -260.6412, -419.4022, -486.2969, -421.5978,\n",
       "         -29.6512, -249.9574, -271.2870,  -52.1218,  -76.0488, -190.6174,\n",
       "        -188.3594, -133.2872, -201.9915, -112.3499, -345.7244, -273.1459,\n",
       "        -208.6133,  -33.9136, -414.5116, -172.8745, -133.9536, -440.6256,\n",
       "        -447.5640, -307.6598, -100.0914, -449.1730, -197.7748, -381.5724,\n",
       "        -387.4440, -225.7218, -318.5923, -119.4291, -407.4978, -117.7936,\n",
       "        -205.7057, -479.7089, -102.3668, -195.5171, -379.7212, -168.8208,\n",
       "        -391.9598, -384.7391, -262.3494, -195.6018])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(feats_reg) - score(feats_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([0] * len(feats_reg[0]) + [1] * len(feats_adv[0]))\n",
    "scores = np.concatenate((score(feats_reg), score(f)))\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels, scores)\n",
    "auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gram Deviation Loss Detector:\n",
    "\n",
    "- Successful Adversaries (AUROC): `0.7030564379258805`\n",
    "- Failed Adversaries (AUROC): `0.5845281134654501`\n",
    "- Percent of adversaries failed: `0.08449074074074074`\n",
    "\n",
    "Gram Margin Loss:\n",
    "\n",
    "- Successful Adversaries (AUROC): `0.5029065593498265`\n",
    "- Failed Adversaries (AUROC): `0.4706757174491286`\n",
    "- Percent of adversaries failed: `0.3460648148148148`\n",
    "\n",
    "Gram Margin Loss (Class Variant):\n",
    "\n",
    "- Successful Adversaries (AUROC): `0.5140263697307398`\n",
    "- Failed Adversaries (AUROC): `0.5171176091325425`\n",
    "- Percent of adversaries failed: `0.35908564814814814`\n",
    "\n",
    "Style Loss:\n",
    "\n",
    "- Successful Adversaries (AUROC): `~0.96`\n",
    "- Failed Adversaries (AUROC): `~0.50`\n",
    "- Percent of adversaries failed: `~0.75`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_p(temp):\n",
    "    temp = temp.reshape(temp.shape[0],temp.shape[1],-1)\n",
    "    temp = ((torch.matmul(temp,temp.transpose(dim0=2,dim1=1)))).sum(dim=2)\n",
    "    return temp.reshape(temp.shape[0],-1)\n",
    "\n",
    "class PGD_margin(nn.Module):\n",
    "    def __init__(self, epsilon=8./255, num_steps=10, step_size=2./255, margin = 20, margin_scale=1.0, verbose=False):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "        self.verbose = verbose\n",
    "        self.margin = margin\n",
    "        self.margin_scale = margin_scale\n",
    "\n",
    "    def forward(self, model, bx, by, feats_reg):\n",
    "        \"\"\"\n",
    "        :param model: the classifier's forward method\n",
    "        :param bx: batch of images\n",
    "        :param by: true labels\n",
    "        :return: perturbed batch of images\n",
    "        \"\"\"\n",
    "        adv_bx = bx.detach()\n",
    "        adv_bx += torch.zeros_like(adv_bx).uniform_(-self.epsilon, self.epsilon)\n",
    "        \n",
    "        for i in range(self.num_steps):\n",
    "            adv_bx.requires_grad_()\n",
    "            \n",
    "            with torch.enable_grad():\n",
    "                logits, feats_adv = model.gram_forward(adv_bx * 2 - 1)\n",
    "                gram_margin = self.margin_scale * gram_margin_loss(feats_reg, feats_adv, self.margin).cuda()\n",
    "                cent_loss = 0.0 * F.cross_entropy(logits, by, reduction='mean').cuda()\n",
    "                \n",
    "                loss = cent_loss + gram_margin\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(\"Step: {}, Cent: {}, Margin Loss: {}, Total Loss: {}\".format(i, cent_loss, gram_margin, loss))\n",
    "            grad = torch.autograd.grad(loss, adv_bx, only_inputs=True)[0]\n",
    "            adv_bx = adv_bx.detach() + self.step_size * torch.sign(grad.detach())\n",
    "            adv_bx = torch.min(torch.max(adv_bx, bx - self.epsilon), bx + self.epsilon).clamp(0, 1)\n",
    "            \n",
    "        return adv_bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers=[1]\n",
    "def cpu(ob):\n",
    "    for i in range(len(ob)):\n",
    "        for j in range(len(ob[i])):\n",
    "            ob[i][j] = ob[i][j].cpu()\n",
    "    return ob\n",
    "    \n",
    "def cuda(ob):\n",
    "    for i in range(len(ob)):\n",
    "        for j in range(len(ob[i])):\n",
    "            ob[i][j] = ob[i][j].cuda()\n",
    "    return ob\n",
    "def calc_gram_dev_target():\n",
    "    return detector.all_test_deviations.mean(axis=0).sum() \n",
    "\n",
    "def G_p_gpu(temp):\n",
    "    temp = temp.reshape(temp.shape[0],temp.shape[1],-1)\n",
    "    temp = ((torch.matmul(temp,temp.transpose(dim0=2,dim1=1)))).sum(dim=2)\n",
    "    return temp.reshape(temp.shape[0],-1)\n",
    "\n",
    "# def G_p_gpu(ob, p):\n",
    "#     temp = ob\n",
    "    \n",
    "#     temp = temp**p\n",
    "#     temp = temp.reshape(temp.shape[0],temp.shape[1],-1)\n",
    "#     temp = ((torch.matmul(temp,temp.transpose(dim0=2,dim1=1)))).sum(dim=2) \n",
    "#     temp = (temp.sign()*torch.abs(temp)**(1/p)).reshape(temp.shape[0],-1)\n",
    "    \n",
    "#     return temp\n",
    "\n",
    "class PGD_Gram(nn.Module):\n",
    "    def __init__(self, epsilon=8/255, num_steps=10, step_size=2/255, grad_sign=True, \n",
    "                         mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5], nrof_classes=10, gram_target = 247, verbose=True):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "        self.grad_sign = grad_sign\n",
    "        \n",
    "        if mean is None:\n",
    "            self.mean = torch.FloatTensor([0.4914, 0.4822, 0.4465]).view(1,3,1,1).cuda()\n",
    "        else:\n",
    "            self.mean = torch.FloatTensor(mean).view(1,3,1,1).cuda()\n",
    "        if std is None:\n",
    "            self.std = torch.FloatTensor([0.2023, 0.1994, 0.2010]).view(1,3,1,1).cuda()\n",
    "        else:\n",
    "            self.std = torch.FloatTensor(std).view(1,3,1,1).cuda()\n",
    "            \n",
    "        self.mns = [cuda(detector.mins[i]) for i in range(nrof_classes)]\n",
    "        self.mxs = [cuda(detector.maxs[i]) for i in range(nrof_classes)]\n",
    "        self.gram_target = gram_target * 0.85\n",
    "        self.verbose = verbose\n",
    "            \n",
    "    def get_deviation(self, feat_list, idx, mins, maxs, power=powers):\n",
    "        batch_deviations = []\n",
    "        for L,feat_L in enumerate(feat_list):\n",
    "            dev = 0\n",
    "            \n",
    "            g_p = G_p_gpu(feat_L)[idx]\n",
    "                \n",
    "            dev +=  (F.relu(mins[L][0]-g_p)/torch.abs(mins[L][0]+10**-6)).sum(dim=1,keepdim=True)\n",
    "            dev +=  (F.relu(g_p-maxs[L][0])/torch.abs(maxs[L][0]+10**-6)).sum(dim=1,keepdim=True)\n",
    "                \n",
    "            batch_deviations.append(dev)\n",
    "                \n",
    "        return batch_deviations\n",
    "        \n",
    "    def gram_loss(self, logits, feats):\n",
    "        confs = F.softmax(logits, dim=1)\n",
    "        _, indices = torch.max(confs, 1)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(10):\n",
    "            idxs = indices == i\n",
    "\n",
    "            if idxs.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            batch_dev = self.get_deviation(feats, idxs, mins=self.mns[i], maxs=self.mxs[i])\n",
    "            batch_dev = torch.squeeze(torch.stack(batch_dev, dim=1))\n",
    "            \n",
    "            loss += batch_dev.sum()\n",
    "                            \n",
    "        return F.relu((loss/logits.shape[0]) - self.gram_target)\n",
    "    \n",
    "    def forward(self, model, bx, by):\n",
    "        \"\"\"\n",
    "        :param model: the classifier's forward method\n",
    "        :param bx: batch of images\n",
    "        :param by: true labels\n",
    "        :return: perturbed batch of images\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        adv_bx = bx.detach()\n",
    "        adv_bx += torch.zeros_like(adv_bx).uniform_(-self.epsilon, self.epsilon)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            adv_bx.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits, feats = model.gram_forward((adv_bx - self.mean)/self.std)\n",
    "                \n",
    "                cent_loss = F.cross_entropy(logits, by, reduction='mean')\n",
    "                gram_loss =  detector.gram_loss(logits, feats)\n",
    "                \n",
    "                loss = cent_loss - gram_loss\n",
    "                                \n",
    "            if self.verbose:\n",
    "                print(\"Step: {}, Cent: {}, Gram: {}, Total Loss: {}\".format(i, cent_loss, gram_loss, loss))\n",
    "            \n",
    "            grad = torch.autograd.grad(loss, adv_bx, only_inputs=True)[0]\n",
    "            adv_bx = adv_bx.detach() + self.step_size * torch.sign(grad.detach())\n",
    "            adv_bx = torch.min(torch.max(adv_bx, bx - self.epsilon), bx + self.epsilon).clamp(0, 1)\n",
    "\n",
    "        return adv_bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
