{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>WRN: Cifar10</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable, grad\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import utils.calculate_log as callog\n",
    "from utils.wrn import WideResNet\n",
    "\n",
    "from utils.detector import Detector, gram_margin_loss\n",
    "import utils.attacks as attacks\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "torch_model = WideResNet(depth=40, widen_factor=2, num_classes=10)\n",
    "\n",
    "torch_model.load(path=\"benchmark_ckpts/cifar10_reg_training_99.pt\")\n",
    "torch_model.cuda()\n",
    "torch_model.params = list(torch_model.parameters())\n",
    "torch_model.eval()\n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In-distribution Datasets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "# mean = np.array([[125.3/255, 123.0/255, 113.9/255]]).T\n",
    "\n",
    "# std = np.array([[63.0/255, 62.1/255.0, 66.7/255.0]]).T\n",
    "# normalize = transforms.Normalize((125.3/255, 123.0/255, 113.9/255), (63.0/255, 62.1/255.0, 66.7/255.0))\n",
    "\n",
    "normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "        \n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.CenterCrop(size=(32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('~/datasets/cifarpy', train=True, download=True,\n",
    "                   transform=transform_train),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('~/datasets/cifarpy', train=False, transform=transform_test),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "detector_data_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "data_train = list(torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('~/datasets/cifarpy', \n",
    "                     train=True, \n",
    "                     transform=detector_data_transform, \n",
    "                     download=True),\n",
    "        batch_size=1, shuffle=False))\n",
    "\n",
    "data_test = list(torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('~/datasets/cifarpy', \n",
    "                     train=False, \n",
    "                     transform=detector_data_transform, \n",
    "                     download=True),\n",
    "        batch_size=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_batch(bxs):\n",
    "    pil = transforms.ToPILImage()\n",
    "    return torch.squeeze(torch.stack([transform_test(pil(bx)) for bx in bxs]), dim=1)\n",
    "\n",
    "def get_batches(d, batch_size=32):\n",
    "    bx = []\n",
    "    by = []\n",
    "    tens = transforms.ToTensor()\n",
    "    for idx in range(0,len(d),batch_size):\n",
    "        bx_batch = torch.squeeze(torch.stack([tens(x[0]) for x in d[idx:idx+batch_size]]),dim=1)\n",
    "        bx.append(bx_batch)\n",
    "        by.append(torch.Tensor([x[1] for x in d[idx:idx+batch_size]]).type(torch.LongTensor))\n",
    "    \n",
    "    return bx, by\n",
    "\n",
    "def advs_p(p, bxs, bys, nrof_batches=None):\n",
    "    if nrof_batches is None:\n",
    "        nrof_batches = len(bxs)\n",
    "        \n",
    "    advs = []\n",
    "    for i in tqdm(range(len(bxs))):\n",
    "        if i >= nrof_batches:\n",
    "            break\n",
    "        \n",
    "        _, feats_reg = torch_model.gram_forward((bxs[i]*2 - 1).cuda())\n",
    "        advs_batch = p(torch_model, bxs[i].cuda(), bys[i].cuda(), feats_reg)\n",
    "\n",
    "        advs.append(advs_batch)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return advs\n",
    "\n",
    "def adversarial_acc(advs, bys):\n",
    "    torch_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(advs)):\n",
    "        pipelined = pipeline_batch(advs[i].cpu())\n",
    "\n",
    "        x = pipelined.cuda()\n",
    "        y = bys[i].numpy()\n",
    "\n",
    "        correct += (y==np.argmax(torch_model(x).detach().cpu().numpy(),axis=1)).sum()\n",
    "        total += y.shape[0]\n",
    "\n",
    "\n",
    "    print(\"Adversarial Test Accuracy: \", correct/total)\n",
    "    \n",
    "def ds_grouped(bxs, bys):\n",
    "    ds = []\n",
    "    for i in range(len(bxs)):\n",
    "        pipelined = pipeline_batch(bxs[i].cpu())\n",
    "        for j in range(len(bxs[i])):\n",
    "            ds.append((pipelined[j], bys[i][j]))\n",
    "    return ds\n",
    "\n",
    "def adversarial_scores(detector, advs_batches, pbar = lambda x, total=None: x):\n",
    "    auroc = []\n",
    "    for batch in pbar(advs_batches):\n",
    "        auroc.append(detector.compute_ood_deviations_batch(batch*2 - 1)[\"AUROC\"])\n",
    "    \n",
    "    return np.mean(auroc)\n",
    "    \n",
    "    \n",
    "def model_accuracy():\n",
    "    torch_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,y in test_loader:\n",
    "        x = x.cuda()\n",
    "        y = y.numpy()\n",
    "        correct += (y==np.argmax(torch_model(x).detach().cpu().numpy(),axis=1)).sum()\n",
    "        total += y.shape[0]\n",
    "        \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Results </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = attacks.PGD(epsilon=8./255, num_steps=10, step_size=2./255).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector(torch_model, data_train, data_test, 512, pbar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating L_Inf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d465ba334e45d796d288a82d9bfa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adversarial Test Accuracy:  0.088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689c6814c36b400795e1a8976ed4d26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9464791337025317"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10 = list(datasets.CIFAR10('~/datasets/cifarpy', train=False))\n",
    "\n",
    "print(\"Calculating L_Inf\")\n",
    "xs, ys = get_batches(cifar10, batch_size=128)\n",
    "# pinf = PGD()\n",
    "# pinf = adversary\n",
    "pinf = PGD_margin().cuda()\n",
    "advs_inf = advs_p(pinf, xs, ys)\n",
    "\n",
    "adversarial_acc(advs_inf, ys)\n",
    "\n",
    "adversarial_scores(detector, advs_inf, pbar=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = list(datasets.CIFAR10('~/datasets/cifarpy', train=False))\n",
    "xs, ys = get_batches(cifar10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker = PGD_margin().cuda()\n",
    "def process_batch(x, y):\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    \n",
    "    ouptut_reg, feats_reg = torch_model.gram_forward(x*2 - 1)\n",
    "    adv_x = attacker(torch_model, x, y, feats_reg)\n",
    "    \n",
    "    output_adv, feats_adv = torch_model.gram_forward(adv_x * 2 - 1)\n",
    "\n",
    "    margin_loss = gram_margin_loss(feats_reg, feats_adv, 20)\n",
    "    \n",
    "    return float(margin_loss), float(output_adv.max(dim=1)[1].eq(y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee11e39d06db44329e25d8d53deceaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017739875242114067 0.15625\n",
      "1.718410611152649 0.15625\n",
      "6.364144325256348 0.15625\n",
      "1.626102328300476 0.09375\n",
      "0.0 0.03125\n",
      "0.0 0.03125\n",
      "2.3059892654418945 0.15625\n",
      "0.0 0.09375\n",
      "0.9669406414031982 0.03125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8b0b9043b9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-2e8fa3f075b8>\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mouptut_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgram_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgram_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/home/joelsimonoff/remote/main/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-8923ba3cdcdc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model, bx, by, feats_reg)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmargin_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_bx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0madv_bx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_bx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0madv_bx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_bx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/home/joelsimonoff/remote/main/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i, x in tqdm(enumerate(xs), total=len(xs)):\n",
    "    if i % 5 != 0:\n",
    "        continue\n",
    "        \n",
    "    loss, accuracy = process_batch(x, ys[i])\n",
    "    \n",
    "    print(loss, accuracy/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19279666803777218"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_p(temp):\n",
    "    temp = temp.reshape(temp.shape[0],temp.shape[1],-1)\n",
    "    temp = ((torch.matmul(temp,temp.transpose(dim0=2,dim1=1)))).sum(dim=2)\n",
    "    return temp.reshape(temp.shape[0],-1)\n",
    "\n",
    "class PGD_margin(nn.Module):\n",
    "    def __init__(self, epsilon=8./255, num_steps=10, step_size=2./255, grad_sign=True):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "        self.grad_sign = grad_sign\n",
    "\n",
    "    def forward(self, model, bx, by, feats_reg):\n",
    "        \"\"\"\n",
    "        :param model: the classifier's forward method\n",
    "        :param bx: batch of images\n",
    "        :param by: true labels\n",
    "        :return: perturbed batch of images\n",
    "        \"\"\"\n",
    "        adv_bx = bx.detach()\n",
    "        adv_bx += torch.zeros_like(adv_bx).uniform_(-self.epsilon, self.epsilon)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            adv_bx.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits, feats_adv = model.gram_forward(adv_bx * 2 - 1)\n",
    "                margin_loss = gram_margin_loss(feats_adv,feats_reg, margin=200).cuda()\n",
    "                \n",
    "                loss = 1/2 * F.cross_entropy(logits, by, reduction='sum') - 1/2 * margin_loss\n",
    "                \n",
    "            grad = torch.autograd.grad(loss, adv_bx, only_inputs=True)[0]\n",
    "            adv_bx = adv_bx.detach() + self.step_size * torch.sign(grad.detach())\n",
    "            adv_bx = torch.min(torch.max(adv_bx, bx - self.epsilon), bx + self.epsilon).clamp(0, 1)\n",
    "            \n",
    "        return adv_bx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark For a Cifar10 WideResNet Trained With OE\n",
      "\n",
      "Model Accuracy On Test Set: 0.5494\n",
      "Adversarial Test Accuracy:  0.0014\n",
      "Detection Benchmark:\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 56.273 75.262 77.094 58.851 84.621\n",
      "\n",
      "Average Gram Deviations For Test Set: 0.6627426147460938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Benchmark For a Cifar10 WideResNet Trained With OE\\n\")\n",
    "\n",
    "print(\"Model Accuracy On Test Set:\", model_accuracy())\n",
    "adversarial_acc(advs_inf, ys)\n",
    "print(\"Detection Benchmark:\")\n",
    "adversarial_scores(advs_inf, ys, powers=powers)\n",
    "\n",
    "print(\"\\nAverage Gram Deviations For Test Set: {}\\n\".format(calc_gram_dev_target()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–––– Create Undetectible Adversarial Attacks ––––\n",
      "Epsilon: 8/255, Num Steps: 10, Step Size: 2/255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35a194135424ba3bcfb34b7fe3f4b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Cent: 0.14773714542388916, Gram: 73.73921203613281, Total Loss: -73.59147644042969\n",
      "Step: 1, Cent: 0.6315072178840637, Gram: 1.5961074829101562, Total Loss: -0.9646002650260925\n",
      "Step: 2, Cent: 1.6839289665222168, Gram: 16.002609252929688, Total Loss: -14.318679809570312\n",
      "Step: 3, Cent: 2.3709537982940674, Gram: 60.39494323730469, Total Loss: -58.023990631103516\n",
      "Step: 4, Cent: 4.563270568847656, Gram: 0.0, Total Loss: 4.563270568847656\n",
      "Step: 5, Cent: 6.832106590270996, Gram: 124.79806518554688, Total Loss: -117.96595764160156\n",
      "Step: 6, Cent: 5.832967281341553, Gram: 0.0, Total Loss: 5.832967281341553\n",
      "Step: 7, Cent: 8.62597942352295, Gram: 36.21221923828125, Total Loss: -27.586238861083984\n",
      "Step: 8, Cent: 7.858233451843262, Gram: 0.0, Total Loss: 7.858233451843262\n",
      "Step: 9, Cent: 10.103129386901855, Gram: 9.694610595703125, Total Loss: 0.40851879119873047\n",
      "Adversarial Test Accuracy:  0.03125\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      "  3.125 32.498 53.872 98.666  0.325\n"
     ]
    }
   ],
   "source": [
    "print(\"–––– Create Undetectible Adversarial Attacks ––––\")\n",
    "print(\"Epsilon: 8/255, Num Steps: 10, Step Size: 2/255\")\n",
    "\n",
    "p_gram = PGD_Gram(gram_target=calc_gram_dev_target(), verbose=True)\n",
    "advs_gram = advs_p(p_gram, xs, ys, nrof_batches = 1)\n",
    "adversarial_acc(advs_gram, ys)\n",
    "adversarial_scores(advs_gram, ys, powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Test Accuracy:  0.0805\n",
      " TNR    AUROC  DTACC  AUIN   AUOUT \n",
      " 10.962 49.469 59.682 43.090 58.825\n"
     ]
    }
   ],
   "source": [
    "adversarial_acc(advs_gram, ys)\n",
    "adversarial_scores(advs_gram, ys, powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_p(temp):\n",
    "    temp = temp.reshape(temp.shape[0],temp.shape[1],-1)\n",
    "    temp = ((torch.matmul(temp,temp.transpose(dim0=2,dim1=1)))).sum(dim=2)\n",
    "    return temp.reshape(temp.shape[0],-1)\n",
    "\n",
    "def proto_gram_margin_loss(feats_reg, feats_adv, margin):\n",
    "    assert len(feats_reg) == len(feats_adv)\n",
    "\n",
    "    layer_deviations = torch.zeros((len(feats_reg), len(feats_reg[0])))\n",
    "    for i in range(len(feats_reg)):\n",
    "        g_p_reg = G_p(feats_reg[i])\n",
    "        g_p_adv = G_p(feats_adv[i])\n",
    "                \n",
    "        clamp = torch.tensor(1.0).cuda()\n",
    "        \n",
    "        orig_max = torch.max(g_p_reg, dim=1)[0]\n",
    "        clamped_max = torch.max(torch.abs(orig_max), clamp)\n",
    "               \n",
    "        max_dist = F.relu(torch.max(g_p_adv, dim=1)[0] - orig_max)/clamped_max\n",
    "        \n",
    "        orig_min = torch.min(g_p_reg, dim=1)[0]\n",
    "        clamped_min = torch.max(torch.abs(orig_min), clamp)\n",
    "        \n",
    "        min_dist = F.relu(orig_min - torch.min(g_p_adv, dim=1)[0])/clamped_min\n",
    "        \n",
    "        layer_deviations[i] = max_dist + min_dist\n",
    "        \n",
    "    return F.relu(margin - layer_deviations.sum(dim=0)).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'powers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c0ea475320ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mPGD_Gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     def __init__(self, epsilon=8/255, num_steps=10, step_size=2/255, grad_sign=True, \n\u001b[1;32m     16\u001b[0m                          mean = None, std = None, nrof_classes=10, gram_target = 247, verbose=True):\n",
      "\u001b[0;32m<ipython-input-18-c0ea475320ce>\u001b[0m in \u001b[0;36mPGD_Gram\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_deviation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpowers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mbatch_deviations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat_L\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'powers' is not defined"
     ]
    }
   ],
   "source": [
    "def calc_gram_dev_target():\n",
    "    return detector.all_test_deviations.mean(axis=0).sum() \n",
    "\n",
    "def G_p_gpu(ob, p):\n",
    "    temp = ob\n",
    "    \n",
    "    temp = temp**p\n",
    "    temp = temp.reshape(temp.shape[0],temp.shape[1],-1)\n",
    "    temp = ((torch.matmul(temp,temp.transpose(dim0=2,dim1=1)))).sum(dim=2) \n",
    "    temp = (temp.sign()*torch.abs(temp)**(1/p)).reshape(temp.shape[0],-1)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "class PGD_Gram(nn.Module):\n",
    "    def __init__(self, epsilon=8/255, num_steps=10, step_size=2/255, grad_sign=True, \n",
    "                         mean = None, std = None, nrof_classes=10, gram_target = 247, verbose=True):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "        self.grad_sign = grad_sign\n",
    "        \n",
    "        if mean is None:\n",
    "            self.mean = torch.FloatTensor([0.4914, 0.4822, 0.4465]).view(1,3,1,1).cuda()\n",
    "        else:\n",
    "            self.mean = torch.FloatTensor(mean).view(1,3,1,1).cuda()\n",
    "        if std is None:\n",
    "            self.std = torch.FloatTensor([0.2023, 0.1994, 0.2010]).view(1,3,1,1).cuda()\n",
    "        else:\n",
    "            self.std = torch.FloatTensor(std).view(1,3,1,1).cuda()\n",
    "            \n",
    "        self.mns = [cuda(detector.mins[i]) for i in range(nrof_classes)]\n",
    "        self.mxs = [cuda(detector.maxs[i]) for i in range(nrof_classes)]\n",
    "        self.gram_target = gram_target * 0.85\n",
    "        self.verbose = verbose\n",
    "            \n",
    "    def get_deviation(self, feat_list, idx, mins, maxs, power=powers):\n",
    "        batch_deviations = []\n",
    "        for L,feat_L in enumerate(feat_list):\n",
    "            dev = 0\n",
    "            for p,P in enumerate(power):\n",
    "                g_p = G_p_gpu(feat_L,P)[idx]\n",
    "                \n",
    "                dev +=  (F.relu(mins[L][p]-g_p)/torch.abs(mins[L][p]+10**-6)).sum(dim=1,keepdim=True)\n",
    "                dev +=  (F.relu(g_p-maxs[L][p])/torch.abs(maxs[L][p]+10**-6)).sum(dim=1,keepdim=True)\n",
    "                \n",
    "                batch_deviations.append(dev)\n",
    "                \n",
    "        return batch_deviations\n",
    "        \n",
    "    def gram_loss(self, feats, logits):\n",
    "        confs = F.softmax(logits, dim=1)\n",
    "        _, indices = torch.max(confs, 1)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(10):\n",
    "            idxs = indices == i\n",
    "\n",
    "            if idxs.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            batch_dev = self.get_deviation(feats, idxs, mins=self.mns[i], maxs=self.mxs[i])\n",
    "            batch_dev = torch.squeeze(torch.stack(batch_dev, dim=1))\n",
    "            \n",
    "            loss += batch_dev.sum()\n",
    "                \n",
    "        return F.relu(loss - logits.shape[0] * self.gram_target)\n",
    "    \n",
    "    def forward(self, model, bx, by):\n",
    "        \"\"\"\n",
    "        :param model: the classifier's forward method\n",
    "        :param bx: batch of images\n",
    "        :param by: true labels\n",
    "        :return: perturbed batch of images\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        adv_bx = bx.detach()\n",
    "        adv_bx += torch.zeros_like(adv_bx).uniform_(-self.epsilon, self.epsilon)\n",
    "\n",
    "        for i in range(self.num_steps):\n",
    "            adv_bx.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits, feats = model.gram_forward((adv_bx - self.mean)/self.std)\n",
    "                \n",
    "                cent_loss = F.cross_entropy(logits, by, reduction='mean')\n",
    "                gram_loss = self.gram_loss(feats, logits)\n",
    "                \n",
    "                loss = cent_loss - gram_loss\n",
    "                \n",
    "            if self.verbose:\n",
    "                print(\"Step: {}, Cent: {}, Gram: {}, Total Loss: {}\".format(i, cent_loss, gram_loss, loss))\n",
    "            \n",
    "            grad = torch.autograd.grad(loss, adv_bx, only_inputs=True)[0]\n",
    "            adv_bx = adv_bx.detach() + self.step_size * torch.sign(grad.detach())\n",
    "            adv_bx = torch.min(torch.max(adv_bx, bx - self.epsilon), bx + self.epsilon).clamp(0, 1)\n",
    "\n",
    "        return adv_bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
